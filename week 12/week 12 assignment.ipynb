{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"dfdata_11.csv\")\n",
        "df = df.fillna(df.mean())\n",
        "# Features and target\n",
        "X = df.drop(\"outcome\", axis=1)\n",
        "y = df[\"outcome\"].astype(int)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Configurations: (iterations, hidden layer structure)\n",
        "configs = [\n",
        "    (1000, (4,)),\n",
        "    (10000, (4,)),\n",
        "    (100000, (4,)),\n",
        "    (1000, (4, 4)),\n",
        "    (10000, (4, 4)),\n",
        "    (100000, (4, 4)),\n",
        "]\n",
        "\n",
        "# Run and collect results\n",
        "results = []\n",
        "for max_iter, layers in configs:\n",
        "    start = time.time()\n",
        "    model = MLPClassifier(hidden_layer_sizes=layers, max_iter=max_iter, random_state=1)\n",
        "    model.fit(X_train, y_train)\n",
        "    end = time.time()\n",
        "\n",
        "    train_err = log_loss(y_train, model.predict_proba(X_train))\n",
        "    val_err = log_loss(y_val, model.predict_proba(X_val))\n",
        "    duration = end - start\n",
        "\n",
        "    results.append({\n",
        "        \"Data size\": len(X_train),\n",
        "        \"Configuration\": f\"{len(layers)} layer(s), nodes: {layers}\",\n",
        "        \"Training error\": round(train_err, 4),\n",
        "        \"Validation error\": round(val_err, 4),\n",
        "        \"Time of execution (s)\": round(duration, 4)\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_krFP44RTYjY",
        "outputId": "bd342042-7dae-4ce3-ce43-b94e8b53abb1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Data size             Configuration  Training error  Validation error  Time of execution (s)\n",
            "   1797741   1 layer(s), nodes: (4,)          0.0019            0.0019                96.9944\n",
            "   1797741   1 layer(s), nodes: (4,)          0.0019            0.0019               101.4970\n",
            "   1797741   1 layer(s), nodes: (4,)          0.0019            0.0019                92.4563\n",
            "   1797741 2 layer(s), nodes: (4, 4)          0.0016            0.0016                87.8583\n",
            "   1797741 2 layer(s), nodes: (4, 4)          0.0016            0.0016                87.6890\n",
            "   1797741 2 layer(s), nodes: (4, 4)          0.0016            0.0016                89.7752\n"
          ]
        }
      ]
    }
  ]
}