{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Week 09 - Machine Learning with Scikit-learn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Hemavathi Karuppaiah"
      ],
      "metadata": {
        "id": "hlSUDjjNPqdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\n",
        "\n",
        "\n",
        "\n",
        "The Python notebook's classification models can reveal their best performer through an evaluation of training and test accuracy scores. The standard Logistic Regression model and the Logistic Regression with L1 penalty (C=10) achieved identical test accuracy scores of 0.718 which outperformed all other models in generalizing to new data. These methods achieved the most suitable combination of model complexity and performance metrics on the patient mortality dataset.\n",
        "\n",
        "The unvalidated RandomForest model showed an extreme training accuracy of 0.9993 but achieved only 0.686 on the test data. The significant difference between training accuracy and testing results shows the model learned the training data by rote instead of extracting meaningful patterns from the data. Therefore it remains unusable despite its advanced algorithm. In comparison the regularized logistic regression models maintained consistent performance throughout training because they did well in both training and testing sets.\n",
        "\n",
        "The Logistic Regression with L1 penalty and C=10 demonstrates superior performance compared to standard Logistic due to its slightly better training accuracy (0.7347 vs. 0.7333) while sharing identical test results. The L1 regularization with its appropriate penalty strength enabled better feature selection along with maintaining generalization capability. The model demonstrates reliable and stable performance across both metrics which establishes it as the top classification model among all tested models in the notebook.\n"
      ],
      "metadata": {
        "id": "E32WnHu2PzoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R01DWBxYPK3P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from patsy import dmatrices\n",
        "import time\n",
        "\n",
        "# Loading the  data\n",
        "df_patients_full = pd.read_csv('./PatientAnalyticFile.csv')\n",
        "\n",
        "# Creating mortality variable\n",
        "df_patients_full['mortality'] = np.where(df_patients_full['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "# Converting DateOfBirth to date and calculate age\n",
        "df_patients_full['DateOfBirth'] = pd.to_datetime(df_patients_full['DateOfBirth'])\n",
        "df_patients_full['Age_years'] = ((pd.to_datetime('2015-01-01') - df_patients_full['DateOfBirth']).dt.days/365.25)\n",
        "\n",
        "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
        "              'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "vars_left = set(df_patients_full.columns) - set(vars_remove)\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model matrices\n",
        "Y, X = dmatrices(formula, df_patients_full)\n",
        "\n",
        "# Split data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, np.ravel(Y),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "6pw_e5jKQYOB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of solvers to test\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "# Results dictionary\n",
        "results = {\n",
        "    'Solver': [],\n",
        "    'Training Accuracy': [],\n",
        "    'Holdout Accuracy': [],\n",
        "    'Time Taken (seconds)': []\n",
        "}"
      ],
      "metadata": {
        "id": "mj2IFmvzQfEX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for solver in solvers:\n",
        "    start_time = time.time()\n",
        "    penalty = 'l2'\n",
        "    if solver == 'liblinear':\n",
        "        penalty = 'l2'\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        solver=solver,\n",
        "        penalty=penalty,\n",
        "        random_state=42,\n",
        "        max_iter=1000\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Making predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculating accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    # Storing the  results\n",
        "    results['Solver'].append(solver)\n",
        "    results['Training Accuracy'].append(train_accuracy)\n",
        "    results['Holdout Accuracy'].append(test_accuracy)\n",
        "    results['Time Taken (seconds)'].append(time_taken)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df['Training Accuracy'] = results_df['Training Accuracy'].map('{:.4f}'.format)\n",
        "results_df['Holdout Accuracy'] = results_df['Holdout Accuracy'].map('{:.4f}'.format)\n",
        "results_df['Time Taken (seconds)'] = results_df['Time Taken (seconds)'].map('{:.4f}'.format)\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hfnjIMWQfp3",
        "outputId": "3ecf50e1-b10f-424f-b290-c246a00da974"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Solver Training Accuracy Holdout Accuracy Time Taken (seconds)\n",
            "0  newton-cg            0.7482           0.7362               0.1974\n",
            "1      lbfgs            0.7482           0.7360               0.8815\n",
            "2  liblinear            0.7479           0.7362               0.1517\n",
            "3        sag            0.7481           0.7362              16.9453\n",
            "4       saga            0.7480           0.7362              12.7136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "The selection of the \"best\" solver demands analyzing several performance metrics based on the presented results. The holdout accuracy of all solvers demonstrated almost equivalent generalization ability since their values spanned from 0.7360 to 0.7362. All solvers demonstrated identical success in optimizing logistic regression since their training accuracy ranged from 0.7479 to 0.7482.\n",
        "\n",
        "Since all models demonstrate equivalent performance the execution time becomes the critical element for determining model rankings. The liblinear solver delivers the fastest execution times of 0.1517 seconds while providing equivalent accuracy to other models in the analysis. The newton-cg solver runs at 0.1974 seconds and lbfgs requires 0.8815 seconds to complete. The sag and saga solvers needed prolonged processing durations of 16.9453 seconds and 12.7136 seconds yet failed to enhance accuracy results.\n",
        "\n",
        "The liblinear solver stands as the optimal choice because it reached equivalent predictive results as other solvers while operating with maximum computational efficiency. The efficiency advantage demonstrated by liblinear would be critical in real-life deployments of either large datasets or models that need recurrent training. The selection of the most efficient modeling approach becomes logical when prediction metrics are equivalent because it optimizes resource utilization without impacting the accuracy."
      ],
      "metadata": {
        "id": "ahXZF1KAQ4Cu"
      }
    }
  ]
}